{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few-shot-Falcon3-7B-Instruct\n",
      "few-shot-Llama-3.1-8B-Instruct\n",
      "few-shot-Mistral-Nemo-Instruct-2407\n",
      "few-shot-Qwen2.5-7B-Instruct\n",
      "fine-tuned-DeepSeek-R1-Distill-Llama-8B\n",
      "fine-tuned-Falcon3-7B-Instruct\n",
      "fine-tuned-Llama-3.1-8B-Instruct\n",
      "fine-tuned-Mistral-Nemo-Instruct-2407\n",
      "fine-tuned-Qwen2.5-7B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# ottengo la lista dei file nella cartella decoding\n",
    "files = os.listdir(\"generations\")\n",
    "\n",
    "# Estrazione dei dataframe e preprocessing\n",
    "model_generations = {}\n",
    "for file in files:\n",
    "    # non considerare le cartelle ma solo i file csv\n",
    "    if file.endswith(\".csv\"):\n",
    "        model = re.sub(r\"^|-en-decoding.csv\", \"\", file) \n",
    "        print(model)\n",
    "        model_generations[model] = pd.read_csv(f\"generations/{file}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risultati per il modello 'few-shot-Falcon3-7B-Instruct':\n",
      "da - Precision: 0.67, Recall: 0.67, F1 Score: 0.67\n",
      "ar - Precision: 0.75, Recall: 0.75, F1 Score: 0.75\n",
      "in - Precision: 0.60, Recall: 0.60, F1 Score: 0.60\n",
      "sn - Precision: 0.22, Recall: 0.21, F1 Score: 0.21\n",
      "sv - Precision: 0.13, Recall: 0.14, F1 Score: 0.13\n",
      "\n",
      "Risultati per il modello 'few-shot-Llama-3.1-8B-Instruct':\n",
      "da - Precision: 0.15, Recall: 0.15, F1 Score: 0.15\n",
      "ar - Precision: 0.58, Recall: 0.58, F1 Score: 0.58\n",
      "in - Precision: 0.46, Recall: 0.46, F1 Score: 0.46\n",
      "sn - Precision: 0.56, Recall: 0.65, F1 Score: 0.60\n",
      "sv - Precision: 0.35, Recall: 0.37, F1 Score: 0.36\n",
      "\n",
      "Risultati per il modello 'few-shot-Mistral-Nemo-Instruct-2407':\n",
      "da - Precision: 0.38, Recall: 0.38, F1 Score: 0.38\n",
      "ar - Precision: 0.40, Recall: 0.40, F1 Score: 0.40\n",
      "in - Precision: 0.54, Recall: 0.54, F1 Score: 0.54\n",
      "sn - Precision: 0.57, Recall: 0.61, F1 Score: 0.59\n",
      "sv - Precision: 0.35, Recall: 0.39, F1 Score: 0.37\n",
      "\n",
      "Risultati per il modello 'few-shot-Qwen2.5-7B-Instruct':\n",
      "da - Precision: 0.77, Recall: 0.77, F1 Score: 0.77\n",
      "ar - Precision: 0.73, Recall: 0.73, F1 Score: 0.73\n",
      "in - Precision: 0.63, Recall: 0.63, F1 Score: 0.63\n",
      "sn - Precision: 0.66, Recall: 0.70, F1 Score: 0.68\n",
      "sv - Precision: 0.38, Recall: 0.42, F1 Score: 0.40\n",
      "\n",
      "Risultati per il modello 'fine-tuned-DeepSeek-R1-Distill-Llama-8B':\n",
      "da - Precision: 0.92, Recall: 0.92, F1 Score: 0.92\n",
      "ar - Precision: 0.77, Recall: 0.77, F1 Score: 0.77\n",
      "in - Precision: 0.94, Recall: 0.94, F1 Score: 0.94\n",
      "sn - Precision: 0.73, Recall: 0.71, F1 Score: 0.72\n",
      "sv - Precision: 0.60, Recall: 0.60, F1 Score: 0.60\n",
      "\n",
      "Risultati per il modello 'fine-tuned-Falcon3-7B-Instruct':\n",
      "da - Precision: 0.85, Recall: 0.85, F1 Score: 0.85\n",
      "ar - Precision: 0.71, Recall: 0.71, F1 Score: 0.71\n",
      "in - Precision: 0.94, Recall: 0.94, F1 Score: 0.94\n",
      "sn - Precision: 0.60, Recall: 0.61, F1 Score: 0.60\n",
      "sv - Precision: 0.55, Recall: 0.54, F1 Score: 0.54\n",
      "\n",
      "Risultati per il modello 'fine-tuned-Llama-3.1-8B-Instruct':\n",
      "da - Precision: 0.88, Recall: 0.88, F1 Score: 0.88\n",
      "ar - Precision: 0.85, Recall: 0.85, F1 Score: 0.85\n",
      "in - Precision: 0.96, Recall: 0.96, F1 Score: 0.96\n",
      "sn - Precision: 0.73, Recall: 0.72, F1 Score: 0.73\n",
      "sv - Precision: 0.61, Recall: 0.60, F1 Score: 0.60\n",
      "\n",
      "Risultati per il modello 'fine-tuned-Mistral-Nemo-Instruct-2407':\n",
      "da - Precision: 0.88, Recall: 0.88, F1 Score: 0.88\n",
      "ar - Precision: 0.77, Recall: 0.77, F1 Score: 0.77\n",
      "in - Precision: 0.98, Recall: 0.98, F1 Score: 0.98\n",
      "sn - Precision: 0.76, Recall: 0.76, F1 Score: 0.76\n",
      "sv - Precision: 0.67, Recall: 0.67, F1 Score: 0.67\n",
      "\n",
      "Risultati per il modello 'fine-tuned-Qwen2.5-7B-Instruct':\n",
      "da - Precision: 0.88, Recall: 0.88, F1 Score: 0.88\n",
      "ar - Precision: 0.71, Recall: 0.71, F1 Score: 0.71\n",
      "in - Precision: 0.96, Recall: 0.96, F1 Score: 0.96\n",
      "sn - Precision: 0.65, Recall: 0.62, F1 Score: 0.64\n",
      "sv - Precision: 0.54, Recall: 0.52, F1 Score: 0.53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "# Funzione per calcolare precisione e recall per ogni label\n",
    "def calculate_precision_recall(predictions, actuals):\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    \n",
    "    # Iteriamo su ciascun key (label) per calcolare precisione e recall\n",
    "    for key in predictions.keys():\n",
    "        pred_value = predictions.get(key)\n",
    "        ref_value = actuals.get(key)\n",
    "\n",
    "       \n",
    "        # Se entrambi sono liste, appianiamo le liste (flatten)\n",
    "        if isinstance(pred_value, list) and isinstance(ref_value, list):\n",
    "            # Appianiamo le liste (flatten) se necessario\n",
    "            pred_value = [item for sublist in pred_value for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "            ref_value = [item for sublist in ref_value for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "            \n",
    "            #print(\"Prima\")\n",
    "            #print(pred_value)\n",
    "            #print(ref_value)\n",
    "\n",
    "            # Trasforma le tuple in liste\n",
    "            pred_value = [list(item) if isinstance(item, tuple) else item for item in pred_value]\n",
    "            ref_value = [list(item) if isinstance(item, tuple) else item for item in ref_value]\n",
    "\n",
    "            # Trasforma le liste dentro le liste in stringhe\n",
    "            pred_value = [str(item) if isinstance(item, list) else item for item in pred_value]\n",
    "            ref_value = [str(item) if isinstance(item, list) else item for item in ref_value]\n",
    "\n",
    "            #print(\"Dopo\")\n",
    "            #print(pred_value)\n",
    "            #print(ref_value)\n",
    "\n",
    "            #print()\n",
    "\n",
    "            # Usa Counter per confrontare le liste\n",
    "            pred_counter = Counter(pred_value)\n",
    "            ref_counter = Counter(ref_value)\n",
    "\n",
    "            # Calcola TP, FP, FN\n",
    "            TP = sum((pred_counter & ref_counter).values())\n",
    "            FP = sum((pred_counter - ref_counter).values())\n",
    "            FN = sum((ref_counter - pred_counter).values())\n",
    "        else:\n",
    "            # Se non sono liste, confronta direttamente i valori\n",
    "            TP = 1 if pred_value == ref_value else 0\n",
    "            FP = 1 if pred_value != ref_value else 0\n",
    "            FN = 1 if ref_value is not None and pred_value != ref_value else 0\n",
    "\n",
    "        # Calcola precisione e recall per la label corrente\n",
    "        precision[key] = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall[key] = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "# Per ogni modello, calcola precisione e recall per ogni label\n",
    "for model in model_generations:\n",
    "    print(f\"Risultati per il modello '{model}':\")\n",
    "\n",
    "    # Convertiamo le colonne 'prediction' e 'actual' da stringa a dizionario\n",
    "    predictions = model_generations[model]['prediction'].apply(ast.literal_eval)\n",
    "    actuals = model_generations[model]['actual'].apply(ast.literal_eval)\n",
    "\n",
    "    # Creiamo un nuovo oggetto per tenere i valori trasformati\n",
    "    for i in range(len(actuals)):\n",
    "        # Prendi il dizionario per ogni riga\n",
    "        actual = actuals[i]\n",
    "        \n",
    "        # Itera sulle chiavi e valori del dizionario\n",
    "        for k, v in actual.items():\n",
    "            if k == 'sv' or k == 'sn':\n",
    "                # Se il valore è una stringa, prova a trasformarlo in una lista\n",
    "                if isinstance(v, str):\n",
    "                    try:\n",
    "                        # Usa ast.literal_eval per trasformare la stringa in una struttura di dati (lista o dizionario)\n",
    "                        actual[k] = ast.literal_eval(v)\n",
    "                    except:\n",
    "                        # Se non riesci a fare la conversione, lascia il valore invariato\n",
    "                        pass\n",
    "                elif isinstance(v, list):\n",
    "                    # Se è una lista, assicuriamoci che sia una lista piatta (flatten)\n",
    "                    actual[k] = [item for sublist in v for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "    \n",
    "        prediction = predictions[i]\n",
    "\n",
    "        # Itera sulle chiavi e valori del dizionario\n",
    "        for k, v in prediction.items():\n",
    "            if k == 'sv' or k == 'sn':\n",
    "                # Se il valore è una stringa, prova a trasformarlo in una lista\n",
    "                if isinstance(v, str):\n",
    "                    try:\n",
    "                        # Usa ast.literal_eval per trasformare la stringa in una struttura di dati (lista o dizionario)\n",
    "                        prediction[k] = ast.literal_eval(v)\n",
    "                    except:\n",
    "                        # Se non riesci a fare la conversione, lascia il valore invariato\n",
    "                        pass\n",
    "                elif isinstance(v, list):\n",
    "                    # Se è una lista, assicuriamoci che sia una lista piatta (flatten)\n",
    "                    prediction[k] = [item for sublist in v for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "    \n",
    "\n",
    "    # Inizializzare variabili per tenere traccia delle metriche\n",
    "    total_precision = {key: 0 for key in ['da', 'ar', 'in', 'sn', 'sv']}\n",
    "    total_recall = {key: 0 for key in ['da', 'ar', 'in', 'sn', 'sv']}\n",
    "    total_count = len(predictions)\n",
    "\n",
    "    # Calcoliamo la precisione e recall per ogni esempio\n",
    "    for i in range(total_count):\n",
    "        prediction = predictions[i]\n",
    "        actual = actuals[i]\n",
    "\n",
    "        #print(prediction)\n",
    "        #print(actual)\n",
    "\n",
    "        precision, recall = calculate_precision_recall(prediction, actual)\n",
    "        \n",
    "        # Aggiorniamo le metriche cumulative, solo se la chiave è presente\n",
    "        for key in total_precision.keys():\n",
    "            if key in precision:  # Solo se la chiave è presente nel dizionario delle predizioni\n",
    "                total_precision[key] += precision[key]\n",
    "            if key in recall:  # Solo se la chiave è presente nel dizionario delle predizioni\n",
    "                total_recall[key] += recall[key]\n",
    "\n",
    "    # Calcoliamo la media delle precisioni e recall\n",
    "    avg_precision = {key: total_precision[key] / total_count for key in total_precision}\n",
    "    avg_recall = {key: total_recall[key] / total_count for key in total_recall}\n",
    "    f1_score = {}\n",
    "    for key in avg_precision:\n",
    "        if (avg_precision[key] + avg_recall[key]) > 0:\n",
    "            f1_score[key] = 2 * avg_precision[key] * avg_recall[key] / (avg_precision[key] + avg_recall[key])\n",
    "        else:\n",
    "            f1_score[key] = 0  # Se la somma di precision e recall è zero, imposta F1 a 0\n",
    "\n",
    "    # Stampa i risultati per ogni modello\n",
    "    for key in avg_precision:\n",
    "        print(f\"{key} - Precision: {avg_precision[key]:.2f}, Recall: {avg_recall[key]:.2f}, F1 Score: {f1_score[key]:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risultati per il modello 'few-shot-Falcon3-7B-Instruct':\n",
      "da - Precision: 0.67, Recall: 0.67, F1 Score: 0.67\n",
      "ar - Precision: 0.75, Recall: 0.75, F1 Score: 0.75\n",
      "in - Precision: 0.60, Recall: 0.60, F1 Score: 0.60\n",
      "sn - Precision: 0.22, Recall: 0.21, F1 Score: 0.21\n",
      "sv - Precision: 0.13, Recall: 0.14, F1 Score: 0.13\n",
      "s - Precision: 0.15, Recall: 0.17, F1 Score: 0.16\n",
      "\n",
      "Risultati per il modello 'few-shot-Llama-3.1-8B-Instruct':\n",
      "da - Precision: 0.15, Recall: 0.15, F1 Score: 0.15\n",
      "ar - Precision: 0.58, Recall: 0.58, F1 Score: 0.58\n",
      "in - Precision: 0.46, Recall: 0.46, F1 Score: 0.46\n",
      "sn - Precision: 0.56, Recall: 0.65, F1 Score: 0.60\n",
      "sv - Precision: 0.35, Recall: 0.37, F1 Score: 0.36\n",
      "s - Precision: 0.44, Recall: 0.50, F1 Score: 0.47\n",
      "\n",
      "Risultati per il modello 'few-shot-Mistral-Nemo-Instruct-2407':\n",
      "da - Precision: 0.38, Recall: 0.38, F1 Score: 0.38\n",
      "ar - Precision: 0.40, Recall: 0.40, F1 Score: 0.40\n",
      "in - Precision: 0.54, Recall: 0.54, F1 Score: 0.54\n",
      "sn - Precision: 0.57, Recall: 0.61, F1 Score: 0.59\n",
      "sv - Precision: 0.35, Recall: 0.39, F1 Score: 0.37\n",
      "s - Precision: 0.42, Recall: 0.49, F1 Score: 0.45\n",
      "\n",
      "Risultati per il modello 'few-shot-Qwen2.5-7B-Instruct':\n",
      "da - Precision: 0.77, Recall: 0.77, F1 Score: 0.77\n",
      "ar - Precision: 0.73, Recall: 0.73, F1 Score: 0.73\n",
      "in - Precision: 0.63, Recall: 0.63, F1 Score: 0.63\n",
      "sn - Precision: 0.66, Recall: 0.70, F1 Score: 0.68\n",
      "sv - Precision: 0.38, Recall: 0.42, F1 Score: 0.40\n",
      "s - Precision: 0.46, Recall: 0.55, F1 Score: 0.50\n",
      "\n",
      "Risultati per il modello 'fine-tuned-DeepSeek-R1-Distill-Llama-8B':\n",
      "da - Precision: 0.92, Recall: 0.92, F1 Score: 0.92\n",
      "ar - Precision: 0.77, Recall: 0.77, F1 Score: 0.77\n",
      "in - Precision: 0.94, Recall: 0.94, F1 Score: 0.94\n",
      "sn - Precision: 0.73, Recall: 0.71, F1 Score: 0.72\n",
      "sv - Precision: 0.60, Recall: 0.60, F1 Score: 0.60\n",
      "s - Precision: 0.66, Recall: 0.65, F1 Score: 0.66\n",
      "\n",
      "Risultati per il modello 'fine-tuned-Falcon3-7B-Instruct':\n",
      "da - Precision: 0.85, Recall: 0.85, F1 Score: 0.85\n",
      "ar - Precision: 0.71, Recall: 0.71, F1 Score: 0.71\n",
      "in - Precision: 0.94, Recall: 0.94, F1 Score: 0.94\n",
      "sn - Precision: 0.60, Recall: 0.61, F1 Score: 0.60\n",
      "sv - Precision: 0.55, Recall: 0.54, F1 Score: 0.54\n",
      "s - Precision: 0.57, Recall: 0.57, F1 Score: 0.57\n",
      "\n",
      "Risultati per il modello 'fine-tuned-Llama-3.1-8B-Instruct':\n",
      "da - Precision: 0.88, Recall: 0.88, F1 Score: 0.88\n",
      "ar - Precision: 0.85, Recall: 0.85, F1 Score: 0.85\n",
      "in - Precision: 0.96, Recall: 0.96, F1 Score: 0.96\n",
      "sn - Precision: 0.73, Recall: 0.72, F1 Score: 0.73\n",
      "sv - Precision: 0.61, Recall: 0.60, F1 Score: 0.60\n",
      "s - Precision: 0.67, Recall: 0.66, F1 Score: 0.66\n",
      "\n",
      "Risultati per il modello 'fine-tuned-Mistral-Nemo-Instruct-2407':\n",
      "da - Precision: 0.88, Recall: 0.88, F1 Score: 0.88\n",
      "ar - Precision: 0.77, Recall: 0.77, F1 Score: 0.77\n",
      "in - Precision: 0.98, Recall: 0.98, F1 Score: 0.98\n",
      "sn - Precision: 0.76, Recall: 0.76, F1 Score: 0.76\n",
      "sv - Precision: 0.67, Recall: 0.67, F1 Score: 0.67\n",
      "s - Precision: 0.71, Recall: 0.72, F1 Score: 0.71\n",
      "\n",
      "Risultati per il modello 'fine-tuned-Qwen2.5-7B-Instruct':\n",
      "da - Precision: 0.88, Recall: 0.88, F1 Score: 0.88\n",
      "ar - Precision: 0.71, Recall: 0.71, F1 Score: 0.71\n",
      "in - Precision: 0.96, Recall: 0.96, F1 Score: 0.96\n",
      "sn - Precision: 0.65, Recall: 0.62, F1 Score: 0.64\n",
      "sv - Precision: 0.54, Recall: 0.52, F1 Score: 0.53\n",
      "s - Precision: 0.63, Recall: 0.59, F1 Score: 0.61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "# Funzione per calcolare precisione e recall per ogni label\n",
    "def calculate_precision_recall(predictions, actuals):\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    \n",
    "    # Iteriamo su ciascun key (label) per calcolare precisione e recall\n",
    "    for key in predictions.keys():\n",
    "        pred_value = predictions.get(key)\n",
    "        ref_value = actuals.get(key)\n",
    "\n",
    "        # Se entrambi sono liste, appianiamo le liste (flatten)\n",
    "        if isinstance(pred_value, list) and isinstance(ref_value, list):\n",
    "            pred_value = [item for sublist in pred_value for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "            ref_value = [item for sublist in ref_value for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "            \n",
    "            pred_value = [list(item) if isinstance(item, tuple) else item for item in pred_value]\n",
    "            ref_value = [list(item) if isinstance(item, tuple) else item for item in ref_value]\n",
    "\n",
    "            pred_value = [str(item) if isinstance(item, list) else item for item in pred_value]\n",
    "            ref_value = [str(item) if isinstance(item, list) else item for item in ref_value]\n",
    "\n",
    "            pred_counter = Counter(pred_value)\n",
    "            ref_counter = Counter(ref_value)\n",
    "\n",
    "            TP = sum((pred_counter & ref_counter).values())\n",
    "            FP = sum((pred_counter - ref_counter).values())\n",
    "            FN = sum((ref_counter - pred_counter).values())\n",
    "        else:\n",
    "            TP = 1 if pred_value == ref_value else 0\n",
    "            FP = 1 if pred_value != ref_value else 0\n",
    "            FN = 1 if ref_value is not None and pred_value != ref_value else 0\n",
    "\n",
    "        precision[key] = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall[key] = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "for model in model_generations:\n",
    "    print(f\"Risultati per il modello '{model}':\")\n",
    "\n",
    "    predictions = model_generations[model]['prediction'].apply(ast.literal_eval)\n",
    "    actuals = model_generations[model]['actual'].apply(ast.literal_eval)\n",
    "\n",
    "    for i in range(len(actuals)):\n",
    "        actual = actuals[i]\n",
    "        prediction = predictions[i]\n",
    "        \n",
    "        def safe_list(value):\n",
    "            if isinstance(value, str):\n",
    "                try:\n",
    "                    return ast.literal_eval(value) if isinstance(ast.literal_eval(value), list) else [ast.literal_eval(value)]\n",
    "                except:\n",
    "                    return [value]  # Se fallisce la conversione, mettiamo la stringa in una lista\n",
    "            return value if isinstance(value, list) else [value]  # Se non è lista, lo trasformiamo in una lista\n",
    "\n",
    "        actual['s'] = safe_list(actual.get('sn', [])) + safe_list(actual.get('sv', []))\n",
    "        prediction['s'] = safe_list(prediction.get('sn', [])) + safe_list(prediction.get('sv', []))\n",
    "\n",
    "                \n",
    "        for k, v in actual.items():\n",
    "            if k in ['sn', 'sv', 's']:\n",
    "                if isinstance(v, str):\n",
    "                    try:\n",
    "                        actual[k] = ast.literal_eval(v)\n",
    "                    except:\n",
    "                        pass\n",
    "                elif isinstance(v, list):\n",
    "                    actual[k] = [item for sublist in v for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "        \n",
    "        for k, v in prediction.items():\n",
    "            if k in ['sn', 'sv', 's']:\n",
    "                if isinstance(v, str):\n",
    "                    try:\n",
    "                        prediction[k] = ast.literal_eval(v)\n",
    "                    except:\n",
    "                        pass\n",
    "                elif isinstance(v, list):\n",
    "                    prediction[k] = [item for sublist in v for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "    \n",
    "    total_precision = {key: 0 for key in ['da', 'ar', 'in', 'sn', 'sv', 's']}\n",
    "    total_recall = {key: 0 for key in ['da', 'ar', 'in', 'sn', 'sv', 's']}\n",
    "    total_count = len(predictions)\n",
    "\n",
    "    for i in range(total_count):\n",
    "        prediction = predictions[i]\n",
    "        actual = actuals[i]\n",
    "\n",
    "        precision, recall = calculate_precision_recall(prediction, actual)\n",
    "        \n",
    "        for key in total_precision.keys():\n",
    "            if key in precision:\n",
    "                total_precision[key] += precision[key]\n",
    "            if key in recall:\n",
    "                total_recall[key] += recall[key]\n",
    "\n",
    "    avg_precision = {key: total_precision[key] / total_count for key in total_precision}\n",
    "    avg_recall = {key: total_recall[key] / total_count for key in total_recall}\n",
    "    f1_score = {}\n",
    "    for key in avg_precision:\n",
    "        if (avg_precision[key] + avg_recall[key]) > 0:\n",
    "            f1_score[key] = 2 * avg_precision[key] * avg_recall[key] / (avg_precision[key] + avg_recall[key])\n",
    "        else:\n",
    "            f1_score[key] = 0\n",
    "\n",
    "    for key in avg_precision:\n",
    "        print(f\"{key} - Precision: {avg_precision[key]:.2f}, Recall: {avg_recall[key]:.2f}, F1 Score: {f1_score[key]:.2f}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
